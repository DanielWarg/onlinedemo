# === Tailscale Funnel demo deploy (local Mac) ===
#
# Copy to: deploy/tailscale/.env
# NOTE: .env is gitignored by repo root .gitignore.

# Public domain (single host, no subdomain)
DOMAIN_ROOT=example.ts.net

# CORS origin for FastAPI (must match the HTTPS origin used via Funnel)
CORS_ALLOW_ORIGINS=https://example.ts.net

# Basic auth (set your own for demo)
AUTH_MODE=basic
BASIC_AUTH_USER=admin
BASIC_AUTH_PASS=password

# Optional: två roller i Basic Auth (admin/editor)
# - Admin defaultar till BASIC_AUTH_USER/PASS om ej satta.
# - Editor är valfri (om ej satt finns bara admin).
# BASIC_AUTH_ADMIN_USER=admin
# BASIC_AUTH_ADMIN_PASS=password
# BASIC_AUTH_EDITOR_USER=editor
# BASIC_AUTH_EDITOR_PASS=editor-password

# Postgres
POSTGRES_DB=arbetsytan
POSTGRES_USER=arbetsytan
POSTGRES_PASSWORD=change-me
DATABASE_URL=postgresql://arbetsytan:change-me@postgres:5432/arbetsytan

# Optional
DEMO_MODE=true
FORTKNOX_ENGINE_ID=local_llm
# Live via Fort Knox Local på din Mac (rekommenderat). Starta Fort Knox Local på :8787.
FORTKNOX_TESTMODE=0
FORTKNOX_REMOTE_URL=http://host.docker.internal:8787

# --- Valfritt: Fort Knox via LangChain (opt-in, regressionsäker) ---
# Separat endpoint: POST /api/fortknox/compile/langchain
#
# (A) OpenAI API (demo)
# FORTKNOX_PIPELINE=langchain
# FORTKNOX_LC_PROVIDER=openai
# OPENAI_API_KEY=sk-...               # lägg i .env lokalt (gitignored)
# FORTKNOX_LC_MODEL=gpt-4o-mini       # valfritt, default i kod är gpt-4o-mini
#
# (B) Lokal OpenAI-kompatibel endpoint (t.ex. llama.cpp /v1)
# FORTKNOX_PIPELINE=langchain
# FORTKNOX_LC_PROVIDER=local
# FORTKNOX_LC_BASE_URL=http://host.docker.internal:8080/v1
# FORTKNOX_LC_API_KEY=local
# FORTKNOX_LC_MODEL=ministral

# --- Valfritt: STT via OpenAI (demo) ---
# STT_ENGINE=openai
# OPENAI_API_KEY=sk-...
# OPENAI_STT_MODEL=whisper-1
# OPENAI_STT_LANGUAGE=sv

# Async jobs (STT/LLM) - demo-safe default är AV
# ASYNC_JOBS=0
